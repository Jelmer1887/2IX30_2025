{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas        Tested version: 2.0.3   Your version: 2.0.3\n",
      "numpy         Tested version: 1.21.5  Your version: 1.26.4\n",
      "matplotlib    Tested version: 3.5.3   Your version: 3.5.3\n",
      "scikit-learn  Tested version: 1.2.2   Your version: 1.2.2\n",
      "seaborn                               Your version: 0.13.2\n"
     ]
    }
   ],
   "source": [
    "import time, matplotlib, sklearn\n",
    "\n",
    "# visualizatoin \n",
    "import matplotlib.pyplot as plt  # for plotting general data\n",
    "import seaborn as sns  # for statistical data visualization\n",
    "\n",
    "# data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "# the data intro has been tested with the following versions\n",
    "print(\"pandas        Tested version: 2.0.3   Your version: %s\" % pd.__version__)\n",
    "print(\"numpy         Tested version: 1.21.5  Your version: %s\" % np.__version__)\n",
    "print(\"matplotlib    Tested version: 3.5.3   Your version: %s\" % matplotlib.__version__)\n",
    "print(\"scikit-learn  Tested version: 1.2.2   Your version: %s\" % sklearn.__version__)\n",
    "print(\"seaborn                               Your version: %s\" % sns.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>hospital_id</th>\n",
       "      <th>hospital_death</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>elective_surgery</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>...</th>\n",
       "      <th>aids</th>\n",
       "      <th>cirrhosis</th>\n",
       "      <th>diabetes_mellitus</th>\n",
       "      <th>hepatic_failure</th>\n",
       "      <th>immunosuppression</th>\n",
       "      <th>leukemia</th>\n",
       "      <th>lymphoma</th>\n",
       "      <th>solid_tumor_with_metastasis</th>\n",
       "      <th>apache_3j_bodysystem</th>\n",
       "      <th>apache_2_bodysystem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66154</td>\n",
       "      <td>25312</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>22.73</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>180.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Cardiovascular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114252</td>\n",
       "      <td>59342</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>27.42</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>Respiratory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119783</td>\n",
       "      <td>50777</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.95</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>172.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Metabolic</td>\n",
       "      <td>Metabolic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79267</td>\n",
       "      <td>46918</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>22.64</td>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>165.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>Cardiovascular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92056</td>\n",
       "      <td>34377</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>188.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Trauma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_id  hospital_id  hospital_death   age    bmi  \\\n",
       "0         66154       25312          118               0  68.0  22.73   \n",
       "1        114252       59342           81               0  77.0  27.42   \n",
       "2        119783       50777          118               0  25.0  31.95   \n",
       "3         79267       46918          118               0  81.0  22.64   \n",
       "4         92056       34377           33               0  19.0    NaN   \n",
       "\n",
       "   elective_surgery  ethnicity gender  height  ... aids cirrhosis  \\\n",
       "0                 0  Caucasian      M   180.3  ...  0.0       0.0   \n",
       "1                 0  Caucasian      F   160.0  ...  0.0       0.0   \n",
       "2                 0  Caucasian      F   172.7  ...  0.0       0.0   \n",
       "3                 1  Caucasian      F   165.1  ...  0.0       0.0   \n",
       "4                 0  Caucasian      M   188.0  ...  0.0       0.0   \n",
       "\n",
       "   diabetes_mellitus hepatic_failure immunosuppression  leukemia  lymphoma  \\\n",
       "0                1.0             0.0               0.0       0.0       0.0   \n",
       "1                1.0             0.0               0.0       0.0       0.0   \n",
       "2                0.0             0.0               0.0       0.0       0.0   \n",
       "3                0.0             0.0               0.0       0.0       0.0   \n",
       "4                0.0             0.0               0.0       0.0       0.0   \n",
       "\n",
       "   solid_tumor_with_metastasis  apache_3j_bodysystem  apache_2_bodysystem  \n",
       "0                          0.0                Sepsis       Cardiovascular  \n",
       "1                          0.0           Respiratory          Respiratory  \n",
       "2                          0.0             Metabolic            Metabolic  \n",
       "3                          0.0        Cardiovascular       Cardiovascular  \n",
       "4                          0.0                Trauma               Trauma  \n",
       "\n",
       "[5 rows x 186 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# description\n",
    "description = pd.read_csv('./data/WiDS_Datathon_2020_Dictionary.csv')\n",
    "description_dict = description.set_index('Variable Name').to_dict(orient='index')\n",
    "# data\n",
    "df = pd.read_csv('./data/training_v2.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Variable Name</th>\n",
       "      <th>Unit of Measure</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>identifier</td>\n",
       "      <td>encounter_id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>integer</td>\n",
       "      <td>Unique identifier associated with a patient un...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>identifier</td>\n",
       "      <td>hospital_id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>integer</td>\n",
       "      <td>Unique identifier associated with a hospital</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>identifier</td>\n",
       "      <td>patient_id</td>\n",
       "      <td>NaN</td>\n",
       "      <td>integer</td>\n",
       "      <td>Unique identifier associated with a patient</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>demographic</td>\n",
       "      <td>hospital_death</td>\n",
       "      <td>NaN</td>\n",
       "      <td>binary</td>\n",
       "      <td>Whether the patient died during this hospitali...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>demographic</td>\n",
       "      <td>age</td>\n",
       "      <td>Years</td>\n",
       "      <td>numeric</td>\n",
       "      <td>The age of the patient on unit admission</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>APACHE comorbidity</td>\n",
       "      <td>lymphoma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>binary</td>\n",
       "      <td>Whether the patient has been diagnosed with no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>APACHE comorbidity</td>\n",
       "      <td>solid_tumor_with_metastasis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>binary</td>\n",
       "      <td>Whether the patient has been diagnosed with an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>APACHE grouping</td>\n",
       "      <td>apache_3j_bodysystem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>string</td>\n",
       "      <td>Admission diagnosis group for APACHE III</td>\n",
       "      <td>Cardiovascular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>APACHE grouping</td>\n",
       "      <td>apache_2_bodysystem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>string</td>\n",
       "      <td>Admission diagnosis group for APACHE II</td>\n",
       "      <td>Respiratory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>GOSSIS example prediction</td>\n",
       "      <td>pred</td>\n",
       "      <td>NaN</td>\n",
       "      <td>numeric</td>\n",
       "      <td>Example mortality prediction, shared as a 'bas...</td>\n",
       "      <td>0.000921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Category                Variable Name Unit of Measure  \\\n",
       "0                   identifier                 encounter_id             NaN   \n",
       "1                   identifier                  hospital_id             NaN   \n",
       "2                   identifier                   patient_id             NaN   \n",
       "3                  demographic               hospital_death             NaN   \n",
       "4                  demographic                          age           Years   \n",
       "..                         ...                          ...             ...   \n",
       "183         APACHE comorbidity                     lymphoma             NaN   \n",
       "184         APACHE comorbidity  solid_tumor_with_metastasis             NaN   \n",
       "185            APACHE grouping         apache_3j_bodysystem             NaN   \n",
       "186            APACHE grouping          apache_2_bodysystem             NaN   \n",
       "187  GOSSIS example prediction                         pred             NaN   \n",
       "\n",
       "    Data Type                                        Description  \\\n",
       "0     integer  Unique identifier associated with a patient un...   \n",
       "1     integer       Unique identifier associated with a hospital   \n",
       "2     integer        Unique identifier associated with a patient   \n",
       "3      binary  Whether the patient died during this hospitali...   \n",
       "4     numeric           The age of the patient on unit admission   \n",
       "..        ...                                                ...   \n",
       "183    binary  Whether the patient has been diagnosed with no...   \n",
       "184    binary  Whether the patient has been diagnosed with an...   \n",
       "185    string           Admission diagnosis group for APACHE III   \n",
       "186    string            Admission diagnosis group for APACHE II   \n",
       "187   numeric  Example mortality prediction, shared as a 'bas...   \n",
       "\n",
       "            Example  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3                 0  \n",
       "4               NaN  \n",
       "..              ...  \n",
       "183               1  \n",
       "184               1  \n",
       "185  Cardiovascular  \n",
       "186     Respiratory  \n",
       "187        0.000921  \n",
       "\n",
       "[188 rows x 6 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "We aim to perform:\n",
    "- Missing value handling by k-nearest neighbours\n",
    "- Categorical data conversion to dummies\n",
    "\n",
    "Later we will explorer:\n",
    "- Class imbalance handling techniques:\n",
    "    - relabeling\n",
    "    - over/undersampling\n",
    "    - reweighing\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# -- preprocessing parameters -- #\n",
    "data_split = {\n",
    "    'train' :    .7,    # 70% of the data for training\n",
    "    'test' :     .1,    # 10% of the data for testing (evaluation after training, chapter 4!)\n",
    "    'validate' : .2     # 20% of the data for validation (evaluation during training / model selection, chapter 3!)\n",
    "}\n",
    "seed = 42\n",
    "max_missing = .75 # maximum missing values in a column\n",
    "\n",
    "# -- features that shouldn't be used in the model, as they're either identifiers or other predictor models -- #\n",
    "target_feature = 'hospital_death'\n",
    "identification_features = ['encounter_id', 'patient_id', 'hospital_id', 'icu_id']\n",
    "baseline_features = ['apache_4a_hospital_death_prob', 'apache_4a_icu_death_prob', 'apache_2_bodysystem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- split the data into train, validation, and test datasets -- #\n",
    "\n",
    "# copy allowed data into the dataset X and target variable y\n",
    "X = df.copy().drop(columns=[target_feature] + identification_features + baseline_features)\n",
    "y = df[target_feature].copy() # contains actual y values\n",
    "y_apache = df['apache_4a_hospital_death_prob'].copy() # contains prediction of y values from the apache model, for comparison\n",
    "\n",
    "# split the data into train, validation, and test datasets\n",
    "X_train, X_temp, y_train, y_temp, y_apache_train, y_apache_temp = train_test_split(\n",
    "    X, y, y_apache, test_size=(data_split['test'] + data_split['validate']), random_state=seed\n",
    ")\n",
    "X_val, X_test, y_val, y_test, y_apache_val, y_apache_test = train_test_split(\n",
    "    X_temp, y_temp, y_apache_temp, test_size=(data_split['test'] / (data_split['test'] + data_split['validate'])), random_state=seed\n",
    ")\n",
    "del X_temp, y_temp, y_apache_temp # remove temporary datasets (shouldn't be used anymore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Variables\n",
    "\n",
    "### Model Datasets:\n",
    "\n",
    "- `X_train`: Training dataset features. Use this dataset to train your model.\n",
    "- `y_train`: Training dataset target variable. Use this dataset to train your model.\n",
    "- `X_val`: Validation dataset features. Use this dataset to validate your model during training.\n",
    "- `y_val`: Validation dataset target variable. Use this dataset to validate your model during training.\n",
    "- `X_test`: Test dataset features. Use this dataset to evaluate your model after training.\n",
    "- `y_test`: Test dataset target variable. Use this dataset to evaluate your model after training.\n",
    "\n",
    "### Apache Datasets:\n",
    "- `y_apache_train`: Series containing the APACHE model predictions for the training dataset.\n",
    "- `y_apache_val`: Series containing the APACHE model predictions for the validation dataset.\n",
    "- `y_apache_test`: Series containing the APACHE model predictions for the test dataset.\n",
    "\n",
    "### Variables:\n",
    "\n",
    "- `target_feature`: The target variable for prediction, in this case, 'hospital_death'.\n",
    "- `identification_features`: List of features used for identification purposes, not for model training.\n",
    "- `baseline_features`: List of baseline features that should not be used in the model.\n",
    "- `data_split`: Dictionary containing the proportions for splitting the data into training, validation, and test sets.\n",
    "- `seed`: Random seed for reproducibility.\n",
    "- `max_missing`: Maximum allowed proportion of missing values in a column.\n",
    "- `description`: DataFrame containing the description of each variable in the dataset.\n",
    "- `description_dict`: Dictionary containing the description of each variable in the dataset.\n",
    "\n",
    "> note: the unsplit datasets are still available, but there is no excuse for using them! PREVENT DATA SPILLING!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preproccessing is done in a pipeline that allows for easily repeatable steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropMissingValues(dataset: pd.DataFrame, threshhold: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drops columns from the dataset that have more missing values than the given threshold.\n",
    "    \"\"\"\n",
    "\n",
    "    missingvalues = dataset.isna().sum()            # count missing values in each column\n",
    "    max_allowed_missing = threshhold * len(dataset) # calculate the maximum allowed missing values\n",
    "    feature_drop_list = missingvalues[missingvalues  > max_allowed_missing].index # get the columns with too many missing values\n",
    "\n",
    "    print(f\"there are {len(feature_drop_list)} columns in the dataset that will be dropped:\")\n",
    "    for i,col in enumerate(feature_drop_list):\n",
    "        print(f\"\\t{i+1} {col} ({100*missingvalues[col]/len(dataset):.2f}% missing)\")\n",
    "    \n",
    "    return dataset.drop(feature_drop_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 45 columns in the dataset that will be dropped:\n",
      "\t1 fio2_apache (77.23% missing)\n",
      "\t2 paco2_apache (77.23% missing)\n",
      "\t3 paco2_for_ph_apache (77.23% missing)\n",
      "\t4 pao2_apache (77.23% missing)\n",
      "\t5 ph_apache (77.23% missing)\n",
      "\t6 h1_diasbp_invasive_max (81.68% missing)\n",
      "\t7 h1_diasbp_invasive_min (81.68% missing)\n",
      "\t8 h1_mbp_invasive_max (81.58% missing)\n",
      "\t9 h1_mbp_invasive_min (81.58% missing)\n",
      "\t10 h1_sysbp_invasive_max (81.67% missing)\n",
      "\t11 h1_sysbp_invasive_min (81.67% missing)\n",
      "\t12 h1_albumin_max (91.37% missing)\n",
      "\t13 h1_albumin_min (91.37% missing)\n",
      "\t14 h1_bilirubin_max (92.23% missing)\n",
      "\t15 h1_bilirubin_min (92.23% missing)\n",
      "\t16 h1_bun_max (81.92% missing)\n",
      "\t17 h1_bun_min (81.92% missing)\n",
      "\t18 h1_calcium_max (82.75% missing)\n",
      "\t19 h1_calcium_min (82.75% missing)\n",
      "\t20 h1_creatinine_max (81.78% missing)\n",
      "\t21 h1_creatinine_min (81.78% missing)\n",
      "\t22 h1_hco3_max (83.02% missing)\n",
      "\t23 h1_hco3_min (83.02% missing)\n",
      "\t24 h1_hemaglobin_max (79.85% missing)\n",
      "\t25 h1_hemaglobin_min (79.85% missing)\n",
      "\t26 h1_hematocrit_max (80.14% missing)\n",
      "\t27 h1_hematocrit_min (80.14% missing)\n",
      "\t28 h1_lactate_max (92.03% missing)\n",
      "\t29 h1_lactate_min (92.03% missing)\n",
      "\t30 h1_platelets_max (82.58% missing)\n",
      "\t31 h1_platelets_min (82.58% missing)\n",
      "\t32 h1_potassium_max (78.69% missing)\n",
      "\t33 h1_potassium_min (78.69% missing)\n",
      "\t34 h1_sodium_max (79.22% missing)\n",
      "\t35 h1_sodium_min (79.22% missing)\n",
      "\t36 h1_wbc_max (82.91% missing)\n",
      "\t37 h1_wbc_min (82.91% missing)\n",
      "\t38 h1_arterial_pco2_max (82.96% missing)\n",
      "\t39 h1_arterial_pco2_min (82.96% missing)\n",
      "\t40 h1_arterial_ph_max (83.49% missing)\n",
      "\t41 h1_arterial_ph_min (83.49% missing)\n",
      "\t42 h1_arterial_po2_max (82.95% missing)\n",
      "\t43 h1_arterial_po2_min (82.95% missing)\n",
      "\t44 h1_pao2fio2ratio_max (87.47% missing)\n",
      "\t45 h1_pao2fio2ratio_min (87.47% missing)\n",
      "there are 45 columns in the dataset that will be dropped:\n",
      "\t1 fio2_apache (77.64% missing)\n",
      "\t2 paco2_apache (77.64% missing)\n",
      "\t3 paco2_for_ph_apache (77.64% missing)\n",
      "\t4 pao2_apache (77.64% missing)\n",
      "\t5 ph_apache (77.64% missing)\n",
      "\t6 h1_diasbp_invasive_max (81.66% missing)\n",
      "\t7 h1_diasbp_invasive_min (81.66% missing)\n",
      "\t8 h1_mbp_invasive_max (81.55% missing)\n",
      "\t9 h1_mbp_invasive_min (81.55% missing)\n",
      "\t10 h1_sysbp_invasive_max (81.63% missing)\n",
      "\t11 h1_sysbp_invasive_min (81.63% missing)\n",
      "\t12 h1_albumin_max (91.74% missing)\n",
      "\t13 h1_albumin_min (91.74% missing)\n",
      "\t14 h1_bilirubin_max (92.52% missing)\n",
      "\t15 h1_bilirubin_min (92.52% missing)\n",
      "\t16 h1_bun_max (81.96% missing)\n",
      "\t17 h1_bun_min (81.96% missing)\n",
      "\t18 h1_calcium_max (82.76% missing)\n",
      "\t19 h1_calcium_min (82.76% missing)\n",
      "\t20 h1_creatinine_max (81.84% missing)\n",
      "\t21 h1_creatinine_min (81.84% missing)\n",
      "\t22 h1_hco3_max (83.01% missing)\n",
      "\t23 h1_hco3_min (83.01% missing)\n",
      "\t24 h1_hemaglobin_max (79.74% missing)\n",
      "\t25 h1_hemaglobin_min (79.74% missing)\n",
      "\t26 h1_hematocrit_max (80.11% missing)\n",
      "\t27 h1_hematocrit_min (80.11% missing)\n",
      "\t28 h1_lactate_max (91.99% missing)\n",
      "\t29 h1_lactate_min (91.99% missing)\n",
      "\t30 h1_platelets_max (82.56% missing)\n",
      "\t31 h1_platelets_min (82.56% missing)\n",
      "\t32 h1_potassium_max (78.74% missing)\n",
      "\t33 h1_potassium_min (78.74% missing)\n",
      "\t34 h1_sodium_max (79.39% missing)\n",
      "\t35 h1_sodium_min (79.39% missing)\n",
      "\t36 h1_wbc_max (82.83% missing)\n",
      "\t37 h1_wbc_min (82.83% missing)\n",
      "\t38 h1_arterial_pco2_max (82.63% missing)\n",
      "\t39 h1_arterial_pco2_min (82.63% missing)\n",
      "\t40 h1_arterial_ph_max (83.07% missing)\n",
      "\t41 h1_arterial_ph_min (83.07% missing)\n",
      "\t42 h1_arterial_po2_max (82.61% missing)\n",
      "\t43 h1_arterial_po2_min (82.61% missing)\n",
      "\t44 h1_pao2fio2ratio_max (87.41% missing)\n",
      "\t45 h1_pao2fio2ratio_min (87.41% missing)\n",
      "there are 45 columns in the dataset that will be dropped:\n",
      "\t1 fio2_apache (76.80% missing)\n",
      "\t2 paco2_apache (76.80% missing)\n",
      "\t3 paco2_for_ph_apache (76.80% missing)\n",
      "\t4 pao2_apache (76.80% missing)\n",
      "\t5 ph_apache (76.80% missing)\n",
      "\t6 h1_diasbp_invasive_max (81.88% missing)\n",
      "\t7 h1_diasbp_invasive_min (81.88% missing)\n",
      "\t8 h1_mbp_invasive_max (81.93% missing)\n",
      "\t9 h1_mbp_invasive_min (81.93% missing)\n",
      "\t10 h1_sysbp_invasive_max (81.87% missing)\n",
      "\t11 h1_sysbp_invasive_min (81.87% missing)\n",
      "\t12 h1_albumin_max (90.93% missing)\n",
      "\t13 h1_albumin_min (90.93% missing)\n",
      "\t14 h1_bilirubin_max (92.00% missing)\n",
      "\t15 h1_bilirubin_min (92.00% missing)\n",
      "\t16 h1_bun_max (81.36% missing)\n",
      "\t17 h1_bun_min (81.36% missing)\n",
      "\t18 h1_calcium_max (82.42% missing)\n",
      "\t19 h1_calcium_min (82.42% missing)\n",
      "\t20 h1_creatinine_max (81.18% missing)\n",
      "\t21 h1_creatinine_min (81.18% missing)\n",
      "\t22 h1_hco3_max (82.53% missing)\n",
      "\t23 h1_hco3_min (82.53% missing)\n",
      "\t24 h1_hemaglobin_max (78.86% missing)\n",
      "\t25 h1_hemaglobin_min (78.86% missing)\n",
      "\t26 h1_hematocrit_max (79.35% missing)\n",
      "\t27 h1_hematocrit_min (79.35% missing)\n",
      "\t28 h1_lactate_max (91.74% missing)\n",
      "\t29 h1_lactate_min (91.74% missing)\n",
      "\t30 h1_platelets_max (81.90% missing)\n",
      "\t31 h1_platelets_min (81.90% missing)\n",
      "\t32 h1_potassium_max (77.90% missing)\n",
      "\t33 h1_potassium_min (77.90% missing)\n",
      "\t34 h1_sodium_max (78.50% missing)\n",
      "\t35 h1_sodium_min (78.50% missing)\n",
      "\t36 h1_wbc_max (82.13% missing)\n",
      "\t37 h1_wbc_min (82.13% missing)\n",
      "\t38 h1_arterial_pco2_max (82.23% missing)\n",
      "\t39 h1_arterial_pco2_min (82.23% missing)\n",
      "\t40 h1_arterial_ph_max (82.70% missing)\n",
      "\t41 h1_arterial_ph_min (82.70% missing)\n",
      "\t42 h1_arterial_po2_max (82.23% missing)\n",
      "\t43 h1_arterial_po2_min (82.23% missing)\n",
      "\t44 h1_pao2fio2ratio_max (87.33% missing)\n",
      "\t45 h1_pao2fio2ratio_min (87.33% missing)\n"
     ]
    }
   ],
   "source": [
    "# Missing value handling:\n",
    "# - drop columns with more than max_missing missing values\n",
    "# - impute missing values in the remaining columns\n",
    "\n",
    "X_train = dropMissingValues(X_train, max_missing)\n",
    "X_val = dropMissingValues(X_val, max_missing)\n",
    "X_test = dropMissingValues(X_test, max_missing)\n",
    "\n",
    "# impute missing values in the remaining columns, using the k-NN algorithm\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "numerical_transformer = Pipeline(steps=[('imputer', imputer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Categorical re-encoding -- #\n",
    "# - one-hot encoding for categorical variables\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encode_to_dummies', OneHotEncoder(drop='first', sparse_output=False, handle_unknown=\"ignore\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (64199, 174)\n"
     ]
    }
   ],
   "source": [
    "# -- Pileline -- #\n",
    "\n",
    "# - define the column transformer\n",
    "basic_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, make_column_selector(dtype_exclude=object)), # apply numerical processing to numbers\n",
    "        ('cat', categorical_transformer, make_column_selector(dtype_include=object)) # ... and categorical to objects\n",
    "    ]\n",
    ")\n",
    "\n",
    "# compute pipeline metadata on training set (the same will be used for validation and test set)\n",
    "basic_preprocessor.fit(X_train) # no supervised information is used here, so we can use the training data only\n",
    "\n",
    "# apply the pipeline to the datasets\n",
    "X_train = basic_preprocessor.transform(X_train)\n",
    "X_val = basic_preprocessor.transform(X_val)\n",
    "X_test = basic_preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, KNNImputer())]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000025A9616A6B0&gt;),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;encode_to_dummies&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000025A96168A00&gt;)])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, KNNImputer())]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000025A9616A6B0&gt;),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;encode_to_dummies&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000025A96168A00&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000025A9616A6B0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNNImputer</label><div class=\"sk-toggleable__content\"><pre>KNNImputer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000025A96168A00&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('num',\n",
       "                                 Pipeline(steps=[('imputer', KNNImputer())]),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x0000025A9616A6B0>),\n",
       "                                ('cat',\n",
       "                                 Pipeline(steps=[('encode_to_dummies',\n",
       "                                                  OneHotEncoder(drop='first',\n",
       "                                                                handle_unknown='ignore',\n",
       "                                                                sparse_output=False))]),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x0000025A96168A00>)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(basic_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: ['num__age' 'num__bmi' 'num__elective_surgery' 'num__height'\n",
      " 'num__pre_icu_los_days' 'num__readmission_status' 'num__weight'\n",
      " 'num__albumin_apache' 'num__apache_2_diagnosis'\n",
      " 'num__apache_3j_diagnosis' 'num__apache_post_operative' 'num__arf_apache'\n",
      " 'num__bilirubin_apache' 'num__bun_apache' 'num__creatinine_apache'\n",
      " 'num__gcs_eyes_apache' 'num__gcs_motor_apache' 'num__gcs_unable_apache'\n",
      " 'num__gcs_verbal_apache' 'num__glucose_apache' 'num__heart_rate_apache'\n",
      " 'num__hematocrit_apache' 'num__intubated_apache' 'num__map_apache'\n",
      " 'num__resprate_apache' 'num__sodium_apache' 'num__temp_apache'\n",
      " 'num__urineoutput_apache' 'num__ventilated_apache' 'num__wbc_apache'\n",
      " 'num__d1_diasbp_invasive_max' 'num__d1_diasbp_invasive_min'\n",
      " 'num__d1_diasbp_max' 'num__d1_diasbp_min'\n",
      " 'num__d1_diasbp_noninvasive_max' 'num__d1_diasbp_noninvasive_min'\n",
      " 'num__d1_heartrate_max' 'num__d1_heartrate_min'\n",
      " 'num__d1_mbp_invasive_max' 'num__d1_mbp_invasive_min' 'num__d1_mbp_max'\n",
      " 'num__d1_mbp_min' 'num__d1_mbp_noninvasive_max'\n",
      " 'num__d1_mbp_noninvasive_min' 'num__d1_resprate_max'\n",
      " 'num__d1_resprate_min' 'num__d1_spo2_max' 'num__d1_spo2_min'\n",
      " 'num__d1_sysbp_invasive_max' 'num__d1_sysbp_invasive_min'\n",
      " 'num__d1_sysbp_max' 'num__d1_sysbp_min' 'num__d1_sysbp_noninvasive_max'\n",
      " 'num__d1_sysbp_noninvasive_min' 'num__d1_temp_max' 'num__d1_temp_min'\n",
      " 'num__h1_diasbp_max' 'num__h1_diasbp_min'\n",
      " 'num__h1_diasbp_noninvasive_max' 'num__h1_diasbp_noninvasive_min'\n",
      " 'num__h1_heartrate_max' 'num__h1_heartrate_min' 'num__h1_mbp_max'\n",
      " 'num__h1_mbp_min' 'num__h1_mbp_noninvasive_max'\n",
      " 'num__h1_mbp_noninvasive_min' 'num__h1_resprate_max'\n",
      " 'num__h1_resprate_min' 'num__h1_spo2_max' 'num__h1_spo2_min'\n",
      " 'num__h1_sysbp_max' 'num__h1_sysbp_min' 'num__h1_sysbp_noninvasive_max'\n",
      " 'num__h1_sysbp_noninvasive_min' 'num__h1_temp_max' 'num__h1_temp_min'\n",
      " 'num__d1_albumin_max' 'num__d1_albumin_min' 'num__d1_bilirubin_max'\n",
      " 'num__d1_bilirubin_min' 'num__d1_bun_max' 'num__d1_bun_min'\n",
      " 'num__d1_calcium_max' 'num__d1_calcium_min' 'num__d1_creatinine_max'\n",
      " 'num__d1_creatinine_min' 'num__d1_glucose_max' 'num__d1_glucose_min'\n",
      " 'num__d1_hco3_max' 'num__d1_hco3_min' 'num__d1_hemaglobin_max'\n",
      " 'num__d1_hemaglobin_min' 'num__d1_hematocrit_max'\n",
      " 'num__d1_hematocrit_min' 'num__d1_inr_max' 'num__d1_inr_min'\n",
      " 'num__d1_lactate_max' 'num__d1_lactate_min' 'num__d1_platelets_max'\n",
      " 'num__d1_platelets_min' 'num__d1_potassium_max' 'num__d1_potassium_min'\n",
      " 'num__d1_sodium_max' 'num__d1_sodium_min' 'num__d1_wbc_max'\n",
      " 'num__d1_wbc_min' 'num__h1_glucose_max' 'num__h1_glucose_min'\n",
      " 'num__h1_inr_max' 'num__h1_inr_min' 'num__d1_arterial_pco2_max'\n",
      " 'num__d1_arterial_pco2_min' 'num__d1_arterial_ph_max'\n",
      " 'num__d1_arterial_ph_min' 'num__d1_arterial_po2_max'\n",
      " 'num__d1_arterial_po2_min' 'num__d1_pao2fio2ratio_max'\n",
      " 'num__d1_pao2fio2ratio_min' 'num__aids' 'num__cirrhosis'\n",
      " 'num__diabetes_mellitus' 'num__hepatic_failure' 'num__immunosuppression'\n",
      " 'num__leukemia' 'num__lymphoma' 'num__solid_tumor_with_metastasis'\n",
      " 'cat__ethnicity_Asian' 'cat__ethnicity_Caucasian'\n",
      " 'cat__ethnicity_Hispanic' 'cat__ethnicity_Native American'\n",
      " 'cat__ethnicity_Other/Unknown' 'cat__ethnicity_nan' 'cat__gender_M'\n",
      " 'cat__gender_nan' 'cat__hospital_admit_source_Chest Pain Center'\n",
      " 'cat__hospital_admit_source_Direct Admit'\n",
      " 'cat__hospital_admit_source_Emergency Department'\n",
      " 'cat__hospital_admit_source_Floor' 'cat__hospital_admit_source_ICU'\n",
      " 'cat__hospital_admit_source_ICU to SDU'\n",
      " 'cat__hospital_admit_source_Observation'\n",
      " 'cat__hospital_admit_source_Operating Room'\n",
      " 'cat__hospital_admit_source_Other'\n",
      " 'cat__hospital_admit_source_Other Hospital'\n",
      " 'cat__hospital_admit_source_Other ICU' 'cat__hospital_admit_source_PACU'\n",
      " 'cat__hospital_admit_source_Recovery Room'\n",
      " 'cat__hospital_admit_source_Step-Down Unit (SDU)'\n",
      " 'cat__hospital_admit_source_nan' 'cat__icu_admit_source_Floor'\n",
      " 'cat__icu_admit_source_Operating Room / Recovery'\n",
      " 'cat__icu_admit_source_Other Hospital' 'cat__icu_admit_source_Other ICU'\n",
      " 'cat__icu_admit_source_nan' 'cat__icu_stay_type_readmit'\n",
      " 'cat__icu_stay_type_transfer' 'cat__icu_type_CSICU' 'cat__icu_type_CTICU'\n",
      " 'cat__icu_type_Cardiac ICU' 'cat__icu_type_MICU'\n",
      " 'cat__icu_type_Med-Surg ICU' 'cat__icu_type_Neuro ICU'\n",
      " 'cat__icu_type_SICU' 'cat__apache_3j_bodysystem_Gastrointestinal'\n",
      " 'cat__apache_3j_bodysystem_Genitourinary'\n",
      " 'cat__apache_3j_bodysystem_Gynecological'\n",
      " 'cat__apache_3j_bodysystem_Hematological'\n",
      " 'cat__apache_3j_bodysystem_Metabolic'\n",
      " 'cat__apache_3j_bodysystem_Musculoskeletal/Skin'\n",
      " 'cat__apache_3j_bodysystem_Neurological'\n",
      " 'cat__apache_3j_bodysystem_Respiratory'\n",
      " 'cat__apache_3j_bodysystem_Sepsis' 'cat__apache_3j_bodysystem_Trauma'\n",
      " 'cat__apache_3j_bodysystem_nan']\n"
     ]
    }
   ],
   "source": [
    "#convert output to pandas dataframe\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=basic_preprocessor.get_feature_names_out())\n",
    "X_val = pd.DataFrame(X_val, columns=basic_preprocessor.get_feature_names_out())\n",
    "X_test = pd.DataFrame(X_test, columns=basic_preprocessor.get_feature_names_out())\n",
    "\n",
    "print(f\"columns: {basic_preprocessor.get_feature_names_out()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a new directory\n",
    "output_dir = 'split data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "X_train.to_csv(os.path.join(output_dir, 'X_train.csv'), index=False)\n",
    "X_val.to_csv(os.path.join(output_dir, 'X_val.csv'), index=False)\n",
    "X_test.to_csv(os.path.join(output_dir, 'X_test.csv'), index=False)\n",
    "\n",
    "y_train.to_csv(os.path.join(output_dir, 'y_train.csv'), index=False)\n",
    "y_val.to_csv(os.path.join(output_dir, 'y_val.csv'), index=False)\n",
    "y_test.to_csv(os.path.join(output_dir, 'y_test.csv'), index=False)\n",
    "\n",
    "y_apache_train.to_csv(os.path.join(output_dir, 'y_apache_train.csv'), index=False)\n",
    "y_apache_val.to_csv(os.path.join(output_dir, 'y_apache_val.csv'), index=False)\n",
    "y_apache_test.to_csv(os.path.join(output_dir, 'y_apache_test.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "group11Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
